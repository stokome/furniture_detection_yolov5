{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAE8_aittOcP",
        "outputId": "50b1f4b5-b19e-4ee0-9f49-06b8f1439520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15921, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 15921 (delta 16), reused 24 (delta 9), pack-reused 15880\u001b[K\n",
            "Receiving objects: 100% (15921/15921), 14.60 MiB | 22.34 MiB/s, done.\n",
            "Resolving deltas: 100% (10915/10915), done.\n"
          ]
        }
      ],
      "source": [
        "# Clonning yolov5 repo to our google colab workspace\n",
        "!git clone https://github.com/ultralytics/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSV_K-_wtVrg"
      },
      "outputs": [],
      "source": [
        "# install dependencies as necessary\n",
        "%cd yolov5\n",
        "!pip install -qr requirements.txt\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L21INfHntvKV"
      },
      "outputs": [],
      "source": [
        "#Here I used furniture-ngpea dataset which consist of 161 images of chairs, tables and sofas combines\n",
        "# Download Dataset in yolov5 directory using roboflow package\n",
        "%cd /content/yolov5\n",
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"bys15vogVKtmTbB1lhxM\")\n",
        "project = rf.workspace(\"roboflow-100\").project(\"furniture-ngpea\")\n",
        "dataset = project.version(2).download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d6kMxKhtxjN",
        "outputId": "fcfb8b1c-c73a-4da2-f080-0fe3d8232ff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "names:\n",
            "- Chair\n",
            "- Sofa\n",
            "- Table\n",
            "nc: 3\n",
            "train: furniture-2/train/images\n",
            "val: furniture-2/valid/images\n"
          ]
        }
      ],
      "source": [
        "# this is the YAML file with our data\n",
        "%cat {dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1fZHtYJt0nE",
        "outputId": "4b304882-2e02-4e92-c24c-16058883d3db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-210-gdd10481 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/usr/local/lib/python3.10/dist-packages/pyparsing-3.1.1.dist-info/METADATA'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fusing layers... \n",
            "custom_YOLOv5s summary: 182 layers, 7251912 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "# Loading the model we trained on furnitures dataset using yolov5 earliar\n",
        "model = torch.hub.load('/content/yolov5/', 'custom', path='/content/custom_weight_yolov5/best.pt', source='local', force_reload = True)\n",
        "model.conf = 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hQaQLfSlvF8v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "image_directory = '/content/yolov5/furniture-2/valid/images'\n",
        "labels_directory = '/content/yolov5/furniture-2/valid/labels'\n",
        "labels = {0: \"chair\", 1: \"sofa\", 2: \"table\"} # Labels dictionary\n",
        "global FALSE_PREDICTION\n",
        "FALSE_PREDICTION = 0 # Number of wrong predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oSN96ubiCDjk"
      },
      "outputs": [],
      "source": [
        "# creating a dir to store fp and fn of all classes respectively\n",
        "import os\n",
        "for i in labels:\n",
        "  path1 = f\"/content/diff_fp_fn/{labels[i]}/fp\"\n",
        "  path2 = f\"/content/diff_fp_fn/{labels[i]}/fn\"\n",
        "  if not os.path.exists(path1):\n",
        "    os.makedirs(path1)\n",
        "  if not os.path.exists(path2):\n",
        "    os.makedirs(path2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7U82zcRjwYGC"
      },
      "outputs": [],
      "source": [
        "def save_img(category_path, img1, img2):\n",
        "  # Combine img1 and img2 and save them in respective directory\n",
        "  new_img = cv2.hconcat([img1, img2])\n",
        "  cv2_imshow(new_img)\n",
        "  cv2.imwrite(\"/content/diff_fp_fn/\"+category_path+\".jpg\", new_img)\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    # Returns Intersection over Union of two boxes\n",
        "    x1_min, y1_min, x1_max, y1_max = box1\n",
        "    x2_min, y2_min, x2_max, y2_max = box2\n",
        "\n",
        "    intersection_x1 = max(x1_min, x2_min)\n",
        "    intersection_y1 = max(y1_min, y2_min)\n",
        "    intersection_x2 = min(x1_max, x2_max)\n",
        "    intersection_y2 = min(y1_max, y2_max)\n",
        "\n",
        "    intersection_area = max(0, intersection_x2 - intersection_x1 + 1) * max(0, intersection_y2 - intersection_y1 + 1)\n",
        "\n",
        "    box1_area = (x1_max - x1_min + 1) * (y1_max - y1_min + 1)\n",
        "    box2_area = (x2_max - x2_min + 1) * (y2_max - y2_min + 1)\n",
        "\n",
        "    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
        "\n",
        "    return iou\n",
        "\n",
        "def evaluate_image(img_name):\n",
        "  # Partition of FP and FN images by classes\n",
        "\n",
        "  global FALSE_PREDICTION\n",
        "  image_path = os.path.join(image_directory, img_name+\".jpg\")\n",
        "  labels_path = os.path.join(labels_directory, img_name+\".txt\")\n",
        "  with open(labels_path) as f:\n",
        "    lines = f.readlines()\n",
        "    gt = [float(x) for x in lines[0].split()]\n",
        "\n",
        "  img_gt = cv2.imread(image_path)\n",
        "  img_pred = cv2.imread(image_path)\n",
        "\n",
        "  pred = model(image_path)\n",
        "  plabel, pc, pconf = pred.xyxy[0].cpu().numpy()[:, -1], pred.xyxy[0].cpu().numpy()[:, :-2], pred.xyxy[0].cpu().numpy()[:, -2]\n",
        "  gt_label, gt_c = gt[0], gt[1:]\n",
        "  gtx1 = int(gt_c[0]*1200) - int(gt_c[2]*1200/2)\n",
        "  gty1 = int(gt_c[1]*1200) - int(gt_c[3]*1200/2)\n",
        "  gtx2 = int(gt_c[0]*1200) + int(gt_c[2]*1200/2)\n",
        "  gty2 = int(gt_c[1]*1200) + int(gt_c[3]*1200/2)\n",
        "\n",
        "  if len(plabel) > 1:\n",
        "    # if more than one predicted class\n",
        "    FALSE_PREDICTION+=1\n",
        "    for i in range(len(plabel)):\n",
        "      px1 = int(pc[i][0])\n",
        "      py1 = int(pc[i][1])\n",
        "      px2 = int(pc[i][2])\n",
        "      py2 = int(pc[i][3])\n",
        "      img_pred = cv2.rectangle(img_pred, (px1, py1), (px2, py2), (255, 0, 0), 5)\n",
        "      img_pred = cv2.putText(img_pred, f\"Prediction: {labels[plabel[i]].upper()}({'{:.3f}'.format(pconf[i])})\", (px1, py1+50), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 225, 0), 2)\n",
        "\n",
        "    img_gt = cv2.rectangle(img_gt, (gtx1, gty1), (gtx2, gty2), (255, 0, 0), 5)\n",
        "    img_gt = cv2.putText(img_gt, f\"Ground Truth: {labels[gt_label].upper()}\", (gtx1, gty1 + 50), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 225, 0), 2)\n",
        "\n",
        "    for i in range(len(plabel)):\n",
        "      px1 = int(pc[i][0])\n",
        "      py1 = int(pc[i][1])\n",
        "      px2 = int(pc[i][2])\n",
        "      py2 = int(pc[i][3])\n",
        "\n",
        "      if plabel[i]!=gt_label:\n",
        "        path = f\"{labels[plabel[i]]}/fp/{img_name}\"\n",
        "        save_img(path, img_gt, img_pred)\n",
        "\n",
        "      else:\n",
        "        if calculate_iou((px1, py1, px2, py2), (gtx1, gty1, gtx2, gty2)) < 0.5:\n",
        "          img_p = cv2.imread(image_path)\n",
        "          for i in range(len(plabel)):\n",
        "            if plabel[i]!=gt_label:\n",
        "              px1 = int(pc[i][0])\n",
        "              py1 = int(pc[i][1])\n",
        "              px2 = int(pc[i][2])\n",
        "              py2 = int(pc[i][3])\n",
        "              img_p = cv2.rectangle(img_p, (px1, py1), (px2, py2), (255, 0, 0), 5)\n",
        "              img_p = cv2.putText(img_p, f\"Prediction: {labels[plabel[i]].upper()}({'{:.3f}'.format(pconf[i])})\", (px1, py1+50), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 225, 0), 2)\n",
        "\n",
        "          path = f\"{labels[gt_label]}/fn/{img_name}\"\n",
        "          save_img(path, img_gt, img_p)\n",
        "\n",
        "    if gt_label not in plabel:\n",
        "      path = f\"{labels[gt_label]}/fn/{img_name}\"\n",
        "      save_img(path, img_gt, img_pred)\n",
        "\n",
        "  elif len(plabel) == 0:\n",
        "    # if no prediction by the model\n",
        "    FALSE_PREDICTION+=1\n",
        "    path = f\"{labels[gt_label]}/fn/{img_name}\"\n",
        "    img_gt = cv2.rectangle(img_gt, (gtx1, gty1), (gtx2, gty2), (255, 0, 0), 5)\n",
        "    img_gt = cv2.putText(img_gt, f\"Ground Truth: {labels[gt_label].upper()}\", (gtx1, gty1 + 50), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 225, 0), 2)\n",
        "    save_img(path, img_gt, img_pred)\n",
        "\n",
        "  elif gt_label!=plabel[0]:\n",
        "    # if image is missclassified by image\n",
        "    FALSE_PREDICTION+=1\n",
        "    px1 = int(pc[0][0])\n",
        "    py1 = int(pc[0][1])\n",
        "    px2 = int(pc[0][2])\n",
        "    py2 = int(pc[0][3])\n",
        "    img_pred = cv2.rectangle(img_pred, (px1, py1), (px2, py2), (255, 0, 0), 5)\n",
        "    img_pred = cv2.putText(img_pred, f\"Prediction: {labels[plabel[0]].upper()}({'{:.3f}'.format(pconf[0])})\", (px1, py1+50), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 225, 0), 2)\n",
        "    img_gt = cv2.rectangle(img_gt, (gtx1, gty1), (gtx2, gty2), (255, 0, 0), 2)\n",
        "    img_gt = cv2.putText(img_gt, f\"Ground Truth: {labels[gt_label].upper()}\", (gtx1, gty1 + 50), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 225, 0), 2)\n",
        "    path1 = f\"{labels[plabel[0]]}/fp/{img_name}\"\n",
        "    path2 = f\"{labels[gt_label]}/fn/{img_name}\"\n",
        "    save_img(path1, img_gt, img_pred)\n",
        "    save_img(path2, img_gt, img_pred)\n",
        "\n",
        "  else:\n",
        "    px1 = int(pc[0][0])\n",
        "    py1 = int(pc[0][1])\n",
        "    px2 = int(pc[0][2])\n",
        "    py2 = int(pc[0][3])\n",
        "    img_gt = cv2.rectangle(img_gt, (gtx1, gty1), (gtx2, gty2), (255, 0, 0), 5)\n",
        "    img_gt = cv2.putText(img_gt, f\"Ground Truth: {labels[gt_label].upper()}\", (gtx1, gty1 + 50), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 225, 0), 2)\n",
        "    if calculate_iou((px1, py1, px2, py2), (gtx1, gty1, gtx2, gty2)) < 0.5:\n",
        "      # if iou value is < 0.5 of ground truh and predicted image\n",
        "      FALSE_PREDICTION+=1\n",
        "      path = f\"{labels[gt_label]}/fn/{img_name}\"\n",
        "      save_img(path, img_gt, cv2.imread(image_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttbHkwYBvglM"
      },
      "outputs": [],
      "source": [
        "# Loop over validation dir and evaluate each image individually\n",
        "for filename in os.listdir(image_directory):\n",
        "    evaluate_image(filename.split(\".jpg\")[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MCciyAZafoGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0b3e73e-2a4e-485d-f8fc-b28352c84b02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NO of Images in the Validation SET: 161\n",
            "No of false predictions: 27\n"
          ]
        }
      ],
      "source": [
        "print(f\"NO of Images in the Validation SET: 161\")\n",
        "print(f\"No of false predictions: {FALSE_PREDICTION}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9uW5yERwpMyN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}